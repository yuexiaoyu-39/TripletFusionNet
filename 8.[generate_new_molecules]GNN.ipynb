{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bfb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792ce26",
   "metadata": {},
   "source": [
    "### step1:extract_internal_coordinates_with_atomic_info from dft_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0923fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''处理多个文件的函数'''\n",
    "def extract_internal_coordinates_with_atomic_info(path, atomic_mass_to_element, atomic_mass_to_atomic_number):\n",
    "    \"\"\"\n",
    "    Processes all log files in the specified directory, extracting internal coordinates,\n",
    "    Cartesian coordinates, and energy.\n",
    "    Parameters:\n",
    "    - path: str, the directory path containing log files\n",
    "    - atomic_mass_to_element: dict, mapping from atomic mass to element symbol\n",
    "    - atomic_mass_to_atomic_number: dict, mapping from atomic mass to atomic number\n",
    "    Returns:\n",
    "    - data_dicts: list of dictionaries containing data for each molecule\n",
    "    \"\"\"\n",
    "    data_dicts = []\n",
    "    \n",
    "    # Get the list of .log files in the directory\n",
    "    files = [f for f in os.listdir(path) if f.endswith('.log')]\n",
    "    file_paths = [os.path.join(path, file) for file in files]\n",
    "    \n",
    "    # Add tqdm for progress bar\n",
    "    for file_path in tqdm(file_paths, desc=\"Processing log files\", unit=\"file\"):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            log_content = file.read()\n",
    "            filename = os.path.basename(file_path).split('.')[0]\n",
    "\n",
    "            # Step 1: Extract atomic weights to create atom-to-mass mapping\n",
    "            atom_pattern = re.compile(r\"IAtWgt=\\s+([\\d\\s]+)\")\n",
    "            atom_matches = atom_pattern.findall(log_content)\n",
    "            # Flatten the list and create atom-to-mass mapping (atom indices start from 0)\n",
    "            atomic_weights = [int(weight) for line in atom_matches for weight in line.split()]\n",
    "            atom_to_mass = {i: atomic_weights[i] for i in range(len(atomic_weights))}\n",
    "\n",
    "            # Step 2: Find the last \"Optimized Parameters\" section\n",
    "            optimized_parameters_section = log_content.split(\"Optimized Parameters\")[-1]\n",
    "            # Regex patterns for R, A, D types\n",
    "            pattern_r = re.compile(r\"R\\(([\\d,]+)\\)\\s+([\\d.]+)\")\n",
    "            pattern_a = re.compile(r\"A\\(([\\d,]+)\\)\\s+([\\d.]+)\")\n",
    "            pattern_d = re.compile(r\"D\\(([\\d,]+)\\)\\s+(-?[\\d.]+)\")\n",
    "\n",
    "            # Extract R, A, D values with atomic mass information\n",
    "            data = []\n",
    "            for definition, value in pattern_r.findall(optimized_parameters_section):\n",
    "                atoms = definition.split(\",\")\n",
    "                masses = [atom_to_mass.get(int(atom) - 1, \"Unknown\") for atom in atoms]\n",
    "                data.append([f\"R({definition})\", float(value), masses, filename])\n",
    "            for definition, value in pattern_a.findall(optimized_parameters_section):\n",
    "                atoms = definition.split(\",\")\n",
    "                masses = [atom_to_mass.get(int(atom) - 1, \"Unknown\") for atom in atoms]\n",
    "                data.append([f\"A({definition})\", float(value), masses, filename])\n",
    "            for definition, value in pattern_d.findall(optimized_parameters_section):\n",
    "                atoms = definition.split(\",\")\n",
    "                masses = [atom_to_mass.get(int(atom) - 1, \"Unknown\") for atom in atoms]\n",
    "                data.append([f\"D({definition})\", float(value), masses, filename])\n",
    "            # Create DataFrame for internal coordinates\n",
    "            df = pd.DataFrame(data, columns=[\"Definition\", \"Value\", \"Element Types\", \"File\"])\n",
    "\n",
    "            # Step 3: Extract Cartesian coordinates from \"Standard orientation\"\n",
    "            sections = log_content.split(\"Standard orientation\")\n",
    "            if len(sections) > 1:\n",
    "                last_section = sections[-1]\n",
    "                lines = last_section.strip().split(\"\\n\")\n",
    "                # Find the indices of the coordinate tabel\n",
    "                dash_line_indices = [i for i, line in enumerate(lines) if re.match(r'\\s*-+\\s*', line)]\n",
    "                if len(dash_line_indices) >= 3:\n",
    "                    start = dash_line_indices[1] + 1  # Start after second dashed line\n",
    "                    end = dash_line_indices[2]        # End at third dashed line\n",
    "                    # parse the coordinate lines\n",
    "                    coordinate_data = []\n",
    "                    for line in lines[start:end]:\n",
    "                        tokens = line.strip().split()\n",
    "                        if len(tokens) == 6:\n",
    "                            center_number = int(tokens[0]) - 1  # Adjust index to start from 0 \n",
    "                            atomic_number = int(tokens[1])\n",
    "                            x_coord = float(tokens[3])\n",
    "                            y_coord = float(tokens[4])\n",
    "                            z_coord = float(tokens[5])\n",
    "                            coordinate_data.append([center_number, atomic_number, x_coord, y_coord, z_coord])\n",
    "                    # Creat DataFrame of coordinates\n",
    "                    coord_df = pd.DataFrame(coordinate_data, columns=[\"Atom Index\", \"Atomic Number\", \"X\", \"Y\", \"Z\"])\n",
    "                else:\n",
    "                    print(f\"Warning: Coordinate table not found in {filename}.\")\n",
    "                    coord_df = pd.DataFrame()\n",
    "            else:\n",
    "                print(f\"Warning: 'Standard orientation' not found in {filename}.\")\n",
    "                coord_df = pd.DataFrame()\n",
    "            # Map mass to coord_df\n",
    "            coord_df['Mass'] = coord_df['Atom Index'].map(atom_to_mass)\n",
    "\n",
    "            # Step 4: Extract final energy from the log file\n",
    "            energy_pattern = re.compile(r'SCF Done:\\s+E\\([^\\)]+\\)\\s+=\\s+(-?\\d+\\.\\d+(?:[DE][-+]\\d+)?)')\n",
    "            energy_matches = energy_pattern.findall(log_content)\n",
    "            if energy_matches:\n",
    "                # Handle 'D' notation by replacing it with 'E' for float conversion\n",
    "                energy_values = [e.replace('D', 'E') for e in energy_matches]\n",
    "                final_energy = float(energy_values[-1])\n",
    "            else:\n",
    "                final_energy = None\n",
    "                print(f\"Warning: Final energy not found in {filename}.\")\n",
    "\n",
    "            # Store all data in a dictionary\n",
    "            data_dict = {\n",
    "                'Filename': filename,\n",
    "                'final_energy': final_energy,\n",
    "                'df': df,\n",
    "                'coord_df': coord_df            \n",
    "            }\n",
    "            data_dicts.append(data_dict)\n",
    "    return data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b57abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Your dictionaries\n",
    "atomic_mass_to_element = {\n",
    "    1: \"H\", 11: \"B\", 12: \"C\", 14: \"N\", 16: \"O\", 19: \"F\",\n",
    "    28: \"Si\", 31: \"P\", 32: \"S\", 35: \"Cl\", 79: \"Br\", 80: \"Se\", 127: \"I\",  \n",
    "}\n",
    "\n",
    "atomic_mass_to_atomic_number = {\n",
    "    1: 1, 11: 5, 12: 6, 14: 7, 16: 8, 19: 9,\n",
    "    28: 14, 31: 15, 32: 16, 35: 17, 79: 35, 80: 34, 127: 53\n",
    "}\n",
    "\n",
    "# Path to the directory containing log files\n",
    "log_dir = './data/normal-log-files'\n",
    "\n",
    "# Call the function\n",
    "data_dicts = extract_internal_coordinates_with_atomic_info(\n",
    "    log_dir,\n",
    "    atomic_mass_to_element,\n",
    "    atomic_mass_to_atomic_number\n",
    ")\n",
    "\n",
    "print(f\"Processed {len(data_dicts)} molecules.\")\n",
    "# data_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c250787",
   "metadata": {},
   "source": [
    "#### 在data_dicts中加入HOMO、LUMO、Gap数据以及光谱数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90d97fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOMO</th>\n",
       "      <th>LUMO</th>\n",
       "      <th>Gap</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.471878</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>-0.804732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.199832</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>-0.818722</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378280</td>\n",
       "      <td>-0.297496</td>\n",
       "      <td>-1.194667</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.302149</td>\n",
       "      <td>0.249581</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099167</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HOMO      LUMO       Gap  Filename\n",
       "0  1.471878  0.228315 -0.804732         1\n",
       "1  1.199832 -0.002504 -0.818722        10\n",
       "2  1.378280 -0.297496 -1.194667       100\n",
       "3  0.016300  0.302149  0.249581      1000\n",
       "4 -0.099167 -0.019409  0.050744      1001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = r'C:\\Users\\xiaoyu\\Desktop\\click\\4-raman_info\\Extract_info_from_initial_logs\\Homo_Lumo_scaled.csv'\n",
    "path = './generate_new_molecules/data/Homo_Lumo_scaled.csv'\n",
    "homo_lumo_df = pd.read_csv(path)\n",
    "homo_lumo_df.head()  # 365 rows × 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fd3907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOMO</th>\n",
       "      <th>LUMO</th>\n",
       "      <th>Gap</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>1.14516</td>\n",
       "      <td>-0.54936</td>\n",
       "      <td>-1.253306</td>\n",
       "      <td>7562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HOMO     LUMO       Gap  Filename\n",
       "7147  1.14516 -0.54936 -1.253306      7562"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_lumo_df[homo_lumo_df['Filename']==7562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad7867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path2 = r'C:\\Users\\xiaoyu\\Desktop\\click\\4-raman_info\\3-all_raman_logs_No.2'\n",
    "# # ir_df = pd.read_csv(os.path.join(path2, 'ir_expanded_scaled.csv'), index_col=False)\n",
    "# # ir_df.head()  # 365 rows × 3601 columns\n",
    "\n",
    "# # ir_path = r'C:\\Users\\xiaoyu\\Desktop\\click\\4-raman_info\\Extract_info_from_initial_logs'\n",
    "# # ir_df_2 = pd.read_csv(os.path.join(ir_path, 'ir_expanded_scaled_2.csv'), index_col=False)\n",
    "\n",
    "ir_path = 'generate_new_molecules/data/IrSpecInfo_Scaled.csv'\n",
    "extent_ir_df = pd.read_csv(ir_path, index_col=False)\n",
    "extent_ir_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908471a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raman_df = pd.read_csv(os.path.join(path2, 'raman_expanded_scaled.csv'), index_col=False)\n",
    "# raman_df.head()  # 365 rows × 3601 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e465e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9277,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dicts), \n",
    "# data_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ecd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_rdkit_descriptors_df = pd.read_csv(r'C:\\Users\\xiaoyu\\Desktop\\click\\jupyter\\final_rdkit_descriptors.csv')\n",
    "# final_rdkit_descriptors_df.head()  # (363, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb4cb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Filename': '1',\n",
       " 'final_energy': -1656.87246616,\n",
       " 'df':          Definition     Value     Element Types File\n",
       " 0            R(1,2)    1.5082          [12, 12]    1\n",
       " 1           R(1,44)    1.0957           [12, 1]    1\n",
       " 2           R(1,45)    1.0983           [12, 1]    1\n",
       " 3           R(1,46)    1.0947           [12, 1]    1\n",
       " 4            R(2,3)    1.3982          [12, 12]    1\n",
       " ..              ...       ...               ...  ...\n",
       " 409  D(70,39,40,71)    0.3324    [1, 12, 12, 1]    1\n",
       " 410    D(5,42,43,2)    0.9751  [12, 12, 12, 12]    1\n",
       " 411   D(5,42,43,73) -178.1881   [12, 12, 12, 1]    1\n",
       " 412   D(72,42,43,2)  178.8797   [1, 12, 12, 12]    1\n",
       " 413  D(72,42,43,73)   -0.2835    [1, 12, 12, 1]    1\n",
       " \n",
       " [414 rows x 4 columns],\n",
       " 'coord_df':     Atom Index  Atomic Number         X         Y         Z  Mass\n",
       " 0            0              6 -6.821811 -0.984771 -1.781673    12\n",
       " 1            1              6 -5.376806 -1.083723 -1.360979    12\n",
       " 2            2              6 -4.345296 -0.658895 -2.203867    12\n",
       " 3            3              6 -3.017531 -0.689841 -1.783280    12\n",
       " 4            4              6 -2.680281 -1.153365 -0.506175    12\n",
       " ..         ...            ...       ...       ...       ...   ...\n",
       " 68          68              1 -6.155379  1.580026  2.307833     1\n",
       " 69          69              1 -4.286238  0.673276  3.676884     1\n",
       " 70          70              1 -2.004921  0.524959  2.712168     1\n",
       " 71          71              1 -3.462651 -1.982780  1.316364     1\n",
       " 72          72              1 -5.817328 -1.911067  0.578679     1\n",
       " \n",
       " [73 rows x 6 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d25c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9277\n"
     ]
    }
   ],
   "source": [
    "# 1. 将 data_dicts 转换为以 Filename 为键的字典\n",
    "data_dicts_dict = {data_dict['Filename']: data_dict for data_dict in data_dicts}\n",
    "# 2. 获取在所有数据框中都存在的 filename 列表\n",
    "valid_filenames = set(homo_lumo_df['Filename'])\n",
    "# 3. 更新 data_dicts_dict，仅保留有效的分子\n",
    "data_dicts_dict = {filename: data_dicts_dict[str(filename)] for filename in valid_filenames}\n",
    "# 4. 为 data_dicts 添加 HOMO, LUMO 和 Gap 信息\n",
    "for idx, row in homo_lumo_df.iterrows():\n",
    "    filename = row['Filename']\n",
    "    homo = row['HOMO']\n",
    "    lumo = row['LUMO']\n",
    "    gap = row['Gap']\n",
    "    \n",
    "    # 仅更新 valid_filenames 中存在的分子\n",
    "    if filename in data_dicts_dict:\n",
    "        data_dict = data_dicts_dict[filename]\n",
    "        data_dict['HOMO'] = homo\n",
    "        data_dict['LUMO'] = lumo\n",
    "        data_dict['Gap'] = gap\n",
    "\n",
    "# # 5. 为 data_dicts 添加 IR 光谱\n",
    "# for idx, row in ir_df_2.iterrows():\n",
    "#     filename = row['Filename']\n",
    "#     ir_spectrum = row.drop('Filename').values  # 获取 IR 光谱数据（去除 Filename 列）\n",
    "#     ir_spectrum = np.array(ir_spectrum, dtype=np.float64)\n",
    "    \n",
    "# #     仅更新 valid_filenames 中存在的分子\n",
    "#     if filename in data_dicts_dict:\n",
    "#         data_dict = data_dicts_dict[filename]\n",
    "#         data_dict['IR_Spectrum'] = ir_spectrum\n",
    "\n",
    "# # 6. 为 data_dicts 添加 Raman 光谱\n",
    "# for idx, row in raman_df.iterrows():\n",
    "#     filename = row['Filename']\n",
    "#     raman_spectrum = row.drop('Filename').values  # 获取 Raman 光谱数据（去除 Filename 列）\n",
    "#     raman_spectrum = np.array(raman_spectrum, dtype=np.float64)\n",
    "    \n",
    "#     # 仅更新 valid_filenames 中存在的分子\n",
    "#     if filename in data_dicts_dict:\n",
    "#         data_dict = data_dicts_dict[filename]\n",
    "#         data_dict['Raman_Spectrum'] = raman_spectrum\n",
    "\n",
    "# 7. 为 data_dicts 添加 rdkit描述符\n",
    "# for idx, row in final_rdkit_descriptors_df.iterrows():\n",
    "#     filename = row['Filename']\n",
    "#     rdkit_desc = final_rdkit_descriptors_df.iloc[idx, 2:].values\n",
    "    \n",
    "#     # 仅更新 valid_filenames 中存在的分子\n",
    "#     if filename in data_dicts_dict:\n",
    "#         data_dict = data_dicts_dict[filename]\n",
    "#         data_dict['rdkit_desc'] = rdkit_desc\n",
    "        \n",
    "# 8. 检查最终合并结果（仅输出更新后的有效分子数据）\n",
    "updated_data_dicts = list(data_dicts_dict.values())  # 获取更新后的数据列表\n",
    "i = 0\n",
    "for data_dict in updated_data_dicts:\n",
    "    i+=1\n",
    "#     print(f\"Filename: {data_dict['Filename']}\")\n",
    "#     print(f\"HOMO: {data_dict['HOMO']}, LUMO: {data_dict['LUMO']}, Gap: {data_dict['Gap']}\")\n",
    "#     print(f\"IR Spectrum Length: {len(data_dict['IR_Spectrum'])}\")\n",
    "#     print(f\"Raman Spectrum Length: {len(data_dict['Raman_Spectrum'])}\")\n",
    "#     print(f\"rdkit_desc Length: {len(data_dict['rdkit_desc'])}\")\n",
    "#     print(\"------------------------------------------------------------\")\n",
    "print(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e6e247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9277"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15cc68",
   "metadata": {},
   "source": [
    "# updated_data_dicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c632e4",
   "metadata": {},
   "source": [
    "### step2: Construct GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd50149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Filename': '1',\n",
       " 'final_energy': -1656.87246616,\n",
       " 'df':          Definition     Value     Element Types File\n",
       " 0            R(1,2)    1.5082          [12, 12]    1\n",
       " 1           R(1,44)    1.0957           [12, 1]    1\n",
       " 2           R(1,45)    1.0983           [12, 1]    1\n",
       " 3           R(1,46)    1.0947           [12, 1]    1\n",
       " 4            R(2,3)    1.3982          [12, 12]    1\n",
       " ..              ...       ...               ...  ...\n",
       " 409  D(70,39,40,71)    0.3324    [1, 12, 12, 1]    1\n",
       " 410    D(5,42,43,2)    0.9751  [12, 12, 12, 12]    1\n",
       " 411   D(5,42,43,73) -178.1881   [12, 12, 12, 1]    1\n",
       " 412   D(72,42,43,2)  178.8797   [1, 12, 12, 12]    1\n",
       " 413  D(72,42,43,73)   -0.2835    [1, 12, 12, 1]    1\n",
       " \n",
       " [414 rows x 4 columns],\n",
       " 'coord_df':     Atom Index  Atomic Number         X         Y         Z  Mass\n",
       " 0            0              6 -6.821811 -0.984771 -1.781673    12\n",
       " 1            1              6 -5.376806 -1.083723 -1.360979    12\n",
       " 2            2              6 -4.345296 -0.658895 -2.203867    12\n",
       " 3            3              6 -3.017531 -0.689841 -1.783280    12\n",
       " 4            4              6 -2.680281 -1.153365 -0.506175    12\n",
       " ..         ...            ...       ...       ...       ...   ...\n",
       " 68          68              1 -6.155379  1.580026  2.307833     1\n",
       " 69          69              1 -4.286238  0.673276  3.676884     1\n",
       " 70          70              1 -2.004921  0.524959  2.712168     1\n",
       " 71          71              1 -3.462651 -1.982780  1.316364     1\n",
       " 72          72              1 -5.817328 -1.911067  0.578679     1\n",
       " \n",
       " [73 rows x 6 columns],\n",
       " 'HOMO': 1.471878163483931,\n",
       " 'LUMO': 0.2283149410858311,\n",
       " 'Gap': -0.8047317151600242}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cee9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_debug_molecule_graph(data_dicts, atomic_mass_to_element, atomic_mass_to_atomic_number):\n",
    "    \"\"\"\n",
    "    为多个分子构建分子图,加入HOMO、LUMO、Gap以及红外光谱作为全局信息.\n",
    "\n",
    "    参数：\n",
    "    - data_dicts: 包含每个分子数据的字典列表\n",
    "    - atomic_mass_to_element: dict，原子质量到元素符号的映射\n",
    "    - atomic_mass_to_atomic_number: dict，原子质量到原子序数的映射\n",
    "\n",
    "    返回：\n",
    "    - data_list: 包含每个分子图的 Data 对象列表\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    start_time = time.time()  # Start time for performance tracking\n",
    "    \n",
    "    # Add tqdm for progress bar\n",
    "    for data_dict in tqdm(data_dicts, desc=\"Building molecular graphs\", unit=\"molecule\"):\n",
    "        file_name = data_dict['Filename']\n",
    "        final_energy = data_dict['final_energy']\n",
    "        HOMO = data_dict['HOMO']\n",
    "        LUMO = data_dict['LUMO']\n",
    "        gap = data_dict['Gap']\n",
    "#         ir_spectrum = data_dict['IR_Spectrum']  # 3600维红外光谱数据\n",
    "#         raman_spectrum = data_dict['Raman_Spectrum']  # 2000维拉曼光谱数据        \n",
    "        # 尝试获取 rdkit_desc，若没有则跳过该分子\n",
    "#         rdkit_desc = data_dict.get('rdkit_desc', None)\n",
    "#         if rdkit_desc is None:\n",
    "#             print(f\"警告：文件 {file_name} 中没有 rdkit_desc 字段，跳过此分子。\")\n",
    "#             continue  # 跳过该分子，进入下一个分子的处理\n",
    "        \n",
    "#         print(final_energy)\n",
    "        df = data_dict['df']\n",
    "        coord_df = data_dict['coord_df']\n",
    "        molecule_df = df[df['File'] == file_name]\n",
    "        nodes = {}  # 用于存储节点特征的字典，以原子索引为键\n",
    "        edges = []  # 用于存储带有特征的边的列表\n",
    "    \n",
    "        #  Build nodes using coord_df\n",
    "        for idx, row in coord_df.iterrows():\n",
    "            atom_index = int(row['Atom Index'])\n",
    "            mass = row['Mass']\n",
    "            x_coord = float(row['X'])\n",
    "            y_coord = float(row['Y'])\n",
    "            z_coord = float(row['Z'])\n",
    "            atomic_number = atomic_mass_to_atomic_number.get(mass, None) # 原子序数\n",
    "            element = atomic_mass_to_element.get(mass, 'Unknown')  # 原子种类\n",
    "            if element == 'Unknown':\n",
    "                print(f\"警告：在文件 {file_name} 中未找到原子质量 {mass} 对应的元素。\")\n",
    "            if atomic_number is None:\n",
    "                print(f\"警告：在文件 {file_name} 中未找到原子质量 {mass} 对应的原子序数。\")\n",
    "            nodes[atom_index] = [atom_index, mass, atomic_number, x_coord, y_coord, z_coord]\n",
    "        \n",
    "        # 从内部坐标构建边\n",
    "        for _, row in molecule_df.iterrows():\n",
    "            definition = row['Definition']\n",
    "            value = row['Value']\n",
    "            # 提取原子索引\n",
    "            atoms = [int(a) - 1 for a in definition[2:-1].split(\",\")]\n",
    "            #print(f\"Definition: {definition}, Atom Indices (zero-based): {atoms}\")\n",
    "            # 根据内部坐标类型，添加边信息\n",
    "            if definition.startswith(\"R\"):  # 键长\n",
    "                edges.append((atoms[0], atoms[1], value))\n",
    "    \n",
    "        # 创建 NetworkX 图\n",
    "        G = nx.Graph()\n",
    "        for atom_index, features in nodes.items():\n",
    "            G.add_node(atom_index, features=features)\n",
    "        # 将边添加到图中\n",
    "        existing_edges = set()\n",
    "        for u, v, value in edges:\n",
    "            if (u, v) not in existing_edges and (v, u) not in existing_edges:\n",
    "                G.add_edge(u, v, feature=value)\n",
    "                existing_edges.add((u, v))\n",
    "    \n",
    "        # 从图中提取 edge_index 和 edge_attr\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "    \n",
    "        for u, v, data in G.edges(data=True):\n",
    "            edge_index.append([u, v])\n",
    "            edge_attr.append([data['feature']])\n",
    "    \n",
    "        # 构建节点特征矩阵 x\n",
    "        x = torch.tensor(\n",
    "            [\n",
    "                [atom_index, mass, atomic_number, x_coord, y_coord, z_coord]\n",
    "                for atom_index, (atom_index, mass, atomic_number, x_coord, y_coord, z_coord) in sorted(nodes.items())\n",
    "            ],\n",
    "            dtype=torch.float\n",
    "        )\n",
    "    \n",
    "        # 构建边张量\n",
    "        if edge_index:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "            edge_attr = torch.empty((0,), dtype=torch.float)\n",
    "    \n",
    "        # 创建 PyTorch Geometric Data 对象\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "#         rdkit_desc = np.array(rdkit_desc, dtype=np.float32)\n",
    "        # Add HOMO, LUMO, Gap, IR spectrum, Raman spectrum, and Energy to global features\n",
    "        data.global_features = torch.cat([\n",
    "            torch.tensor([HOMO, LUMO, gap], dtype=torch.float),  # HOMO, LUMO, Gap\n",
    "#             torch.tensor(ir_spectrum, dtype=torch.float),       # IR spectrum (3600 dimensions)\n",
    "#             torch.tensor(raman_spectrum, dtype=torch.float),    # Raman spectrum (3600 dimensions)\n",
    "            torch.tensor([final_energy], dtype=torch.float),     # Energy (if it's part of global information)\n",
    "#             torch.tensor(rdkit_desc, dtype=torch.float),     # rdkit_desc(15)\n",
    "        ], dim=0)\n",
    "\n",
    "        data.file_name = file_name  # 在数据对象中存储文件名\n",
    "#         print(data)\n",
    "        # 添加到列表\n",
    "        data_list.append(data)\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c0aad",
   "metadata": {},
   "source": [
    "传入未加入信息的data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6be1e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = build_and_debug_molecule_graph(data_dicts, atomic_mass_to_element, atomic_mass_to_atomic_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df061057",
   "metadata": {},
   "source": [
    "传加入各种信息的updated_data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4e8561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building molecular graphs: 100%|█████████████████████████████████████████████| 9277/9277 [02:18<00:00, 67.13molecule/s]\n"
     ]
    }
   ],
   "source": [
    "data_list = build_and_debug_molecule_graph(updated_data_dicts, atomic_mass_to_element, atomic_mass_to_atomic_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "832e677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], global_features=[4], file_name='1'),\n",
       " '1',\n",
       " tensor([ 1.4719e+00,  2.2831e-01, -8.0473e-01, -1.6569e+03]),\n",
       " 9277)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0], data_list[0].file_name, data_list[0].global_features, len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82912c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_path = r'C:\\Users\\xiaoyu\\Desktop\\click\\5-提取分子结构向量\\logs\\acceptor45.log'\n",
    "# base_name = os.path.basename(log_path).split('.')[0]\n",
    "# base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b29145",
   "metadata": {},
   "source": [
    "### prediction4-副本中用于预测的分子描述符表格，将其与以下信息合并，这样数据排序是一样的，用同样的切割种子切割出同样的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c79f2e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MaxPartialCharge</th>\n",
       "      <th>BCUT2D_MWHI</th>\n",
       "      <th>BCUT2D_MRLOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cc1ccc(-c2c3ccccc3c(-c3ccccc3)c3c(-c4ccccc4)c4...</td>\n",
       "      <td>2.308093</td>\n",
       "      <td>1.227435</td>\n",
       "      <td>1.227435</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>14.273950</td>\n",
       "      <td>1.474828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Brc1ccc2c(-c3ccccc3)c3c(-c4ccccc4)c4ccccc4c(-c...</td>\n",
       "      <td>3.838429</td>\n",
       "      <td>1.070255</td>\n",
       "      <td>1.070255</td>\n",
       "      <td>0.018137</td>\n",
       "      <td>79.918731</td>\n",
       "      <td>1.623463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Cc1ccc(C#Cc2c3ccccc3c(C#Cc3ccccc3)c3cc4ccccc4c...</td>\n",
       "      <td>3.533942</td>\n",
       "      <td>1.008111</td>\n",
       "      <td>1.008111</td>\n",
       "      <td>0.040654</td>\n",
       "      <td>14.143554</td>\n",
       "      <td>1.459498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>N#Cc1ccc(-c2c3ccccc3c(-c3ccc(I)cc3)c3ccccc23)cc1</td>\n",
       "      <td>9.173973</td>\n",
       "      <td>0.678583</td>\n",
       "      <td>0.678583</td>\n",
       "      <td>0.099110</td>\n",
       "      <td>126.912704</td>\n",
       "      <td>1.485139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>N#Cc1ccc(-c2c3ccccc3c(-c3ccccc3)c3ccccc23)cc1C#N</td>\n",
       "      <td>9.539119</td>\n",
       "      <td>0.398424</td>\n",
       "      <td>0.398424</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>14.279392</td>\n",
       "      <td>1.431312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename                                             SMILES  \\\n",
       "0         1  Cc1ccc(-c2c3ccccc3c(-c3ccccc3)c3c(-c4ccccc4)c4...   \n",
       "1        10  Brc1ccc2c(-c3ccccc3)c3c(-c4ccccc4)c4ccccc4c(-c...   \n",
       "2       100  Cc1ccc(C#Cc2c3ccccc3c(C#Cc3ccccc3)c3cc4ccccc4c...   \n",
       "3      1000   N#Cc1ccc(-c2c3ccccc3c(-c3ccc(I)cc3)c3ccccc23)cc1   \n",
       "4      1001   N#Cc1ccc(-c2c3ccccc3c(-c3ccccc3)c3ccccc23)cc1C#N   \n",
       "\n",
       "   MaxEStateIndex  MinEStateIndex  MinAbsEStateIndex  MaxPartialCharge  \\\n",
       "0        2.308093        1.227435           1.227435         -0.000139   \n",
       "1        3.838429        1.070255           1.070255          0.018137   \n",
       "2        3.533942        1.008111           1.008111          0.040654   \n",
       "3        9.173973        0.678583           0.678583          0.099110   \n",
       "4        9.539119        0.398424           0.398424          0.100532   \n",
       "\n",
       "   BCUT2D_MWHI  BCUT2D_MRLOW  \n",
       "0    14.273950      1.474828  \n",
       "1    79.918731      1.623463  \n",
       "2    14.143554      1.459498  \n",
       "3   126.912704      1.485139  \n",
       "4    14.279392      1.431312  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rdkit_descriptors_df = pd.read_csv('./final_extend_data_rdkit_descriptors.csv')\n",
    "final_rdkit_descriptors_df.head() # (363, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcdabd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共为data_list添加了9277个Filename\n"
     ]
    }
   ],
   "source": [
    "# 3. 为每个分子图添加lifetime值\n",
    "i = 0\n",
    "for data in data_list:\n",
    "    filename = data.file_name  # 获取分子图的文件名\n",
    "#     print('filename in data_list:', filename)\n",
    "    data.lifetime = 0  # 为分子图添加lifetime属性\n",
    "    i+=1\n",
    "print(f'共为data_list添加了{i}个Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e3d01c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9277,\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], global_features=[4], file_name='1', lifetime=0))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list_with_lifetime = [data for data in data_list if hasattr(data, 'lifetime')]\n",
    "len(data_list_with_lifetime), data_list_with_lifetime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91963f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''准备数据（图数据和目标属性）'''\n",
    "def prepare_data_for_training(data_list, target_list, file_names):\n",
    "    prepared_data = []\n",
    "    for i in range(len(data_list)):\n",
    "        data = data_list[i]\n",
    "        global_features = data.global_features  # 获取全局特征 \n",
    "        # 创建 PyTorch Geometric 图数据对象\n",
    "        data_obj = Data(\n",
    "            x=data.x, \n",
    "            edge_index=data.edge_index, \n",
    "            edge_attr=data.edge_attr, \n",
    "            y=torch.tensor([target_list[i]], dtype=torch.float32), \n",
    "            global_features=global_features  # 将全局特征传递给模型\n",
    "        )\n",
    "        data_obj.file_name = file_names[i]\n",
    "        prepared_data.append(data_obj)\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60e1fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''数据准备：切分数据集'''\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb62bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取图数据和对应的lifetime值\n",
    "data_list = [data for data in data_list_with_lifetime]  # 图的全部数据\n",
    "target_list = [data.lifetime for data in data_list_with_lifetime]  # 目标lifetime值\n",
    "file_names = [data.file_name for data in data_list_with_lifetime]  # 文件名列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14b4bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = prepare_data_for_training(data_list, target_list, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "202051b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='1'),\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='2'),\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='3'),\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='4'),\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='5'),\n",
       " Data(x=[70, 6], edge_index=[2, 77], edge_attr=[77, 1], y=[1], global_features=[4], file_name='6'),\n",
       " Data(x=[70, 6], edge_index=[2, 77], edge_attr=[77, 1], y=[1], global_features=[4], file_name='7'),\n",
       " Data(x=[70, 6], edge_index=[2, 77], edge_attr=[77, 1], y=[1], global_features=[4], file_name='8'),\n",
       " Data(x=[70, 6], edge_index=[2, 77], edge_attr=[77, 1], y=[1], global_features=[4], file_name='9'),\n",
       " Data(x=[70, 6], edge_index=[2, 77], edge_attr=[77, 1], y=[1], global_features=[4], file_name='10')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11cef4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], global_features=[4], file_name='1', lifetime=0),\n",
       " Data(x=[73, 6], edge_index=[2, 80], edge_attr=[80, 1], y=[1], global_features=[4], file_name='1'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0], all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7df7ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[36, 6], edge_index=[2, 39], edge_attr=[39, 1], global_features=[4], file_name='E1', lifetime=16.35322976),\n",
       " Data(x=[36, 6], edge_index=[2, 39], edge_attr=[39, 1], y=[1], global_features=[4], file_name='E1'))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0], all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36338774",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''构建GNN模型'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # 添加这行导入\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, global_dim, p=0.2):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.global_dim = global_dim  # 将传入的global_dim存储为实例属性\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "#         '''不含光谱高维信息'''\n",
    "        self.fc1 = nn.Linear(hidden_dim + self.global_dim, 32)   # 输入是 7268，输出 2048\n",
    "        self.bn1 = nn.BatchNorm1d(32)                        # Batch Normalization\n",
    "        self.dropout1 = nn.Dropout(p=p)                      # Dropout 防止过拟合\n",
    "        self.fc2 = nn.Linear(32,output_dim)                  # 最终输出层\n",
    "        \n",
    "        # 权重初始化 (He initialization, Kaiming Normal)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # 使用 He initialization 对每一层的权重进行初始化\n",
    "        init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, global_features):\n",
    "#         print(\"x shape:\", x.shape) \n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))   # 加了relu函数\n",
    "#         print(\"\\nx shape:\", x.shape)   # torch.Size([1351, 64])\n",
    "#         print('global_features shape:', global_features.shape)   # torch.Size([230528])\n",
    "        num_nodes = x.size(0)\n",
    "#         print('num_nodes:', num_nodes)  # 1351\n",
    "        # 初始化全局特征广播的列表\n",
    "        global_features_broadcasted = []\n",
    "        unique_batch = torch.unique(batch)\n",
    "        for i,b in enumerate(unique_batch):\n",
    "            nodes_in_batch = (batch == b).sum().item()  # 计算当前图b的节点数，并存储在nodes_in_batch中。\n",
    "#             print('nodes_in_batch:\\t', nodes_in_batch)\n",
    "            start_idx = i*self.global_dim\n",
    "            end_idx = (i+1)*self.global_dim\n",
    "            global_features_b = global_features[start_idx:end_idx]  # 从global_features中提取图b的全局特征\n",
    "#             print('global_features_b:\\t', global_features_b.shape)\n",
    "            global_features_broadcasted.append(global_features_b.unsqueeze(0).repeat(nodes_in_batch, 1))\n",
    "        global_features_broadcasted = torch.cat(global_features_broadcasted, dim=0)     \n",
    "#         print('global_features_broadcasted shape:', global_features_broadcasted.shape)  #torch.Size([1351, 7204]        \n",
    "        # 拼接节点特征和全局特征\n",
    "        x = torch.cat([x, global_features_broadcasted], dim=-1)\n",
    "#         print('x after cat shape:', x.shape)    # torch.Size([1351, 7268])  7204+64\n",
    "        # 我们需要将每个图的节点特征进行平均，然后传递给全连接层\n",
    "        graph_features = []\n",
    "        start_idx = 0\n",
    "        for b in unique_batch:\n",
    "            end_idx = start_idx + (batch == b).sum().item()\n",
    "            graph_features.append(x[start_idx:end_idx, :].mean(dim=0))\n",
    "            start_idx = end_idx    \n",
    "        # 将图特征表示堆叠起来\n",
    "        graph_features = torch.stack(graph_features)\n",
    "#         print('graph_features shape:\\t', graph_features.shape)  #  torch.Size([32, 7268])\n",
    "        \n",
    "        # 通过全连接层进行预测\n",
    "        graph_features = self.fc1(graph_features)  # 第一层全连接\n",
    "        graph_features = self.bn1(graph_features)  # Batch Normalization\n",
    "        graph_features = F.relu(graph_features)    # ReLU 激活\n",
    "        graph_features = self.dropout1(graph_features)  # Dropout 防止过拟合\n",
    "        \n",
    "        '''含有光谱时，注意使用上面的高维全连接'''\n",
    "        out = self.fc2(graph_features)  # 输出层   \n",
    "\n",
    "        return out, graph_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe21899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_predictions), len(all_true_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36227a40",
   "metadata": {},
   "source": [
    "#### 从保存的训练模型中提取向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "529b991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_features(data_loader):\n",
    "    # 初始化模型\n",
    "    model = GNNModel(6, 64, 1, global_dim=4, p=0)\n",
    "\n",
    "    # 加载模型权重\n",
    "    model_path = 'data/epoch-8-MSE-0.8245-R2-0.7286.pth'  # 替换为你的模型保存路径\n",
    "    model.load_state_dict(torch.load(model_path))  # 加载保存的权重\n",
    "    model.eval()  # 切换到评估模式\n",
    "\n",
    "    # 提取所有训练样本的 global_features\n",
    "    global_features_list = []\n",
    "    labels = []  # 这里假设标签（lifetime）是 `batch_data.y`\n",
    "    filenames = []  # 确保初始化为空列表\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存\n",
    "        for batch_data in data_loader:\n",
    "            # 获取数据\n",
    "            batch = batch_data.batch\n",
    "            x = batch_data.x\n",
    "            edge_index = batch_data.edge_index\n",
    "            edge_attr = batch_data.edge_attr\n",
    "            global_features = batch_data.global_features\n",
    "            lifetime = batch_data.y   \n",
    "            lifetime = lifetime.unsqueeze(1) if lifetime.dim() == 1 else lifetime\n",
    "            \n",
    "            filenames_batch = batch_data.file_name  # 假设文件名存储在 `Filename` 中\n",
    "            # 模型前向传播\n",
    "            _, global_features_out = model(x, edge_index, edge_attr, batch, global_features)\n",
    "\n",
    "            # 将每个批次的 global_features 合并到 global_features 列表中\n",
    "            global_features_list.append(global_features_out.cpu().numpy())  # 需要转为 numpy 数组以便后续处理\n",
    "            labels.append(lifetime.cpu().numpy())  # 目标值\n",
    "            filenames.extend(filenames_batch)  # 追加文件名\n",
    "\n",
    "    # 将所有批次的 global_features 和标签合并为一个矩阵\n",
    "    global_features = np.concatenate(global_features_list, axis=0)  # 合并所有的 global_features\n",
    "    labels = np.concatenate(labels, axis=0)  # 合并所有的标签\n",
    "    \n",
    "    return global_features, labels, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b0be4d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>Lifetime</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118692</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774783</td>\n",
       "      <td>0.057839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700632</td>\n",
       "      <td>0.584249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.585029</td>\n",
       "      <td>1.198794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701808</td>\n",
       "      <td>0.054247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590315</td>\n",
       "      <td>0.583735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729140</td>\n",
       "      <td>0.584781</td>\n",
       "      <td>1.244438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162581</td>\n",
       "      <td>0.107649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.759916</td>\n",
       "      <td>0.056983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414087</td>\n",
       "      <td>0.584021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730253</td>\n",
       "      <td>0.584782</td>\n",
       "      <td>1.195135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088470</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>0.068216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638360</td>\n",
       "      <td>0.579750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540187</td>\n",
       "      <td>0.581928</td>\n",
       "      <td>0.919073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624370</td>\n",
       "      <td>0.068020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672073</td>\n",
       "      <td>0.579613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528409</td>\n",
       "      <td>0.581919</td>\n",
       "      <td>0.911856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>0.606767</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393608</td>\n",
       "      <td>0.493881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199756</td>\n",
       "      <td>0.505564</td>\n",
       "      <td>0.716898</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164071</td>\n",
       "      <td>0.496707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290335</td>\n",
       "      <td>0.507588</td>\n",
       "      <td>0.822531</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042863</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156206</td>\n",
       "      <td>0.505097</td>\n",
       "      <td>0.548009</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.493202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142486</td>\n",
       "      <td>0.504972</td>\n",
       "      <td>0.525525</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9277 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2    3    4         5         6    7         8         9  \\\n",
       "0     0.0  0.173797  0.0  0.0  0.118692  0.096499  0.0  0.774783  0.057839   \n",
       "1     0.0  0.167409  0.0  0.0  0.130081  0.095855  0.0  0.701808  0.054247   \n",
       "2     0.0  0.176095  0.0  0.0  0.162581  0.107649  0.0  0.759916  0.056983   \n",
       "3     0.0  0.172101  0.0  0.0  0.088470  0.093114  0.0  0.639463  0.068216   \n",
       "4     0.0  0.169747  0.0  0.0  0.072914  0.091454  0.0  0.624370  0.068020   \n",
       "...   ...       ...  ...  ...       ...       ...  ...       ...       ...   \n",
       "9272  0.0  0.030859  0.0  0.0  0.030664  0.010164  0.0  0.423441  0.000000   \n",
       "9273  0.0  0.023474  0.0  0.0  0.000000  0.000000  0.0  0.369223  0.000000   \n",
       "9274  0.0  0.024624  0.0  0.0  0.014264  0.001416  0.0  0.437334  0.000000   \n",
       "9275  0.0  0.032188  0.0  0.0  0.042863  0.006269  0.0  0.394387  0.000000   \n",
       "9276  0.0  0.032719  0.0  0.0  0.040905  0.006180  0.0  0.394863  0.000000   \n",
       "\n",
       "       10  ...        25        26   27   28        29        30        31  \\\n",
       "0     0.0  ...  0.700632  0.584249  0.0  0.0  0.698546  0.585029  1.198794   \n",
       "1     0.0  ...  0.590315  0.583735  0.0  0.0  0.729140  0.584781  1.244438   \n",
       "2     0.0  ...  0.414087  0.584021  0.0  0.0  0.730253  0.584782  1.195135   \n",
       "3     0.0  ...  0.638360  0.579750  0.0  0.0  0.540187  0.581928  0.919073   \n",
       "4     0.0  ...  0.672073  0.579613  0.0  0.0  0.528409  0.581919  0.911856   \n",
       "...   ...  ...       ...       ...  ...  ...       ...       ...       ...   \n",
       "9272  0.0  ...  0.000000  0.495008  0.0  0.0  0.192335  0.506369  0.606767   \n",
       "9273  0.0  ...  0.393608  0.493881  0.0  0.0  0.199756  0.505564  0.716898   \n",
       "9274  0.0  ...  0.164071  0.496707  0.0  0.0  0.290335  0.507588  0.822531   \n",
       "9275  0.0  ...  0.000000  0.493374  0.0  0.0  0.156206  0.505097  0.548009   \n",
       "9276  0.0  ...  0.012396  0.493202  0.0  0.0  0.142486  0.504972  0.525525   \n",
       "\n",
       "            32  Lifetime  Filename  \n",
       "0     0.000000       0.0         1  \n",
       "1     0.000000       0.0         2  \n",
       "2     0.000000       0.0         3  \n",
       "3     0.000000       0.0         4  \n",
       "4     0.000000       0.0         5  \n",
       "...        ...       ...       ...  \n",
       "9272  0.013631       0.0      9443  \n",
       "9273  0.008310       0.0      9444  \n",
       "9274  0.011557       0.0      9445  \n",
       "9275  0.014121       0.0      9446  \n",
       "9276  0.014186       0.0      9447  \n",
       "\n",
       "[9277 rows x 34 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "data_loader = DataLoader(all_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "global_features, labels, filenames = get_global_features(data_loader)\n",
    "labels = labels.reshape(-1, 1)\n",
    "features = np.concatenate((global_features, labels), axis=1) \n",
    "# 创建列名: 1, 2, ..., 128 对应每个特征，最后一列为lifetime\n",
    "column_names = [str(i+1) for i in range(global_features.shape[1])] + [\"Lifetime\"]\n",
    "df = pd.DataFrame(features, columns=column_names)\n",
    "df['Filename'] = file_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c5a7ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>Lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118692</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774783</td>\n",
       "      <td>0.057839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.700632</td>\n",
       "      <td>0.584249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.585029</td>\n",
       "      <td>1.198794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701808</td>\n",
       "      <td>0.054247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590315</td>\n",
       "      <td>0.583735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729140</td>\n",
       "      <td>0.584781</td>\n",
       "      <td>1.244438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162581</td>\n",
       "      <td>0.107649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.759916</td>\n",
       "      <td>0.056983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.414087</td>\n",
       "      <td>0.584021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730253</td>\n",
       "      <td>0.584782</td>\n",
       "      <td>1.195135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088470</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>0.068216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638360</td>\n",
       "      <td>0.579750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540187</td>\n",
       "      <td>0.581928</td>\n",
       "      <td>0.919073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624370</td>\n",
       "      <td>0.068020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672073</td>\n",
       "      <td>0.579613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528409</td>\n",
       "      <td>0.581919</td>\n",
       "      <td>0.911856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>9443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>0.606767</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>9444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747993</td>\n",
       "      <td>0.393608</td>\n",
       "      <td>0.493881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199756</td>\n",
       "      <td>0.505564</td>\n",
       "      <td>0.716898</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>9445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063094</td>\n",
       "      <td>0.164071</td>\n",
       "      <td>0.496707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290335</td>\n",
       "      <td>0.507588</td>\n",
       "      <td>0.822531</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9275</th>\n",
       "      <td>9446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042863</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156206</td>\n",
       "      <td>0.505097</td>\n",
       "      <td>0.548009</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>9447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665005</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.493202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142486</td>\n",
       "      <td>0.504972</td>\n",
       "      <td>0.525525</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9277 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename    1         2    3    4         5         6    7         8  \\\n",
       "0           1  0.0  0.173797  0.0  0.0  0.118692  0.096499  0.0  0.774783   \n",
       "1           2  0.0  0.167409  0.0  0.0  0.130081  0.095855  0.0  0.701808   \n",
       "2           3  0.0  0.176095  0.0  0.0  0.162581  0.107649  0.0  0.759916   \n",
       "3           4  0.0  0.172101  0.0  0.0  0.088470  0.093114  0.0  0.639463   \n",
       "4           5  0.0  0.169747  0.0  0.0  0.072914  0.091454  0.0  0.624370   \n",
       "...       ...  ...       ...  ...  ...       ...       ...  ...       ...   \n",
       "9272     9443  0.0  0.030859  0.0  0.0  0.030664  0.010164  0.0  0.423441   \n",
       "9273     9444  0.0  0.023474  0.0  0.0  0.000000  0.000000  0.0  0.369223   \n",
       "9274     9445  0.0  0.024624  0.0  0.0  0.014264  0.001416  0.0  0.437334   \n",
       "9275     9446  0.0  0.032188  0.0  0.0  0.042863  0.006269  0.0  0.394387   \n",
       "9276     9447  0.0  0.032719  0.0  0.0  0.040905  0.006180  0.0  0.394863   \n",
       "\n",
       "             9  ...        24        25        26   27   28        29  \\\n",
       "0     0.057839  ...  0.106762  0.700632  0.584249  0.0  0.0  0.698546   \n",
       "1     0.054247  ...  0.000000  0.590315  0.583735  0.0  0.0  0.729140   \n",
       "2     0.056983  ...  0.004420  0.414087  0.584021  0.0  0.0  0.730253   \n",
       "3     0.068216  ...  0.000000  0.638360  0.579750  0.0  0.0  0.540187   \n",
       "4     0.068020  ...  0.000000  0.672073  0.579613  0.0  0.0  0.528409   \n",
       "...        ...  ...       ...       ...       ...  ...  ...       ...   \n",
       "9272  0.000000  ...  0.920237  0.000000  0.495008  0.0  0.0  0.192335   \n",
       "9273  0.000000  ...  0.747993  0.393608  0.493881  0.0  0.0  0.199756   \n",
       "9274  0.000000  ...  1.063094  0.164071  0.496707  0.0  0.0  0.290335   \n",
       "9275  0.000000  ...  0.686672  0.000000  0.493374  0.0  0.0  0.156206   \n",
       "9276  0.000000  ...  0.665005  0.012396  0.493202  0.0  0.0  0.142486   \n",
       "\n",
       "            30        31        32  Lifetime  \n",
       "0     0.585029  1.198794  0.000000       0.0  \n",
       "1     0.584781  1.244438  0.000000       0.0  \n",
       "2     0.584782  1.195135  0.000000       0.0  \n",
       "3     0.581928  0.919073  0.000000       0.0  \n",
       "4     0.581919  0.911856  0.000000       0.0  \n",
       "...        ...       ...       ...       ...  \n",
       "9272  0.506369  0.606767  0.013631       0.0  \n",
       "9273  0.505564  0.716898  0.008310       0.0  \n",
       "9274  0.507588  0.822531  0.011557       0.0  \n",
       "9275  0.505097  0.548009  0.014121       0.0  \n",
       "9276  0.504972  0.525525  0.014186       0.0  \n",
       "\n",
       "[9277 rows x 34 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('Filename').reindex(file_names).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02efc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_df.to_csv('generate_new_molecules/data/global_features_4_32dim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853b074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b78fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cbb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94d5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6a348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50679185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
